{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM-mPTqwv_X4",
        "outputId": "d8024872-1626-4724-a68c-3438bf338867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tHDjhZDwOiN",
        "outputId": "6681d174-9423-4ef5-9e62-7a9f6b9ee3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Copy of DIAGNOSES_ICD.csv'   DIAGNOSES_ICD.csv.gz   sand_144.py\n",
            " DIAGNOSES_ICD.csv\t      __pycache__\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtZqgC0nwTHE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Project')\n",
        "from sand_144 import SAnD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "voSjbnTgwZch",
        "outputId": "ede4c871-ce0a-481d-a379-f670c7bf7a58"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e4b55564-b1bb-41ed-867b-1e5d419b939c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e4b55564-b1bb-41ed-867b-1e5d419b939c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving ADMISSIONS.csv to ADMISSIONS.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "UkMH-3v2wwHn",
        "outputId": "38655fa0-ec5b-444b-c038-7df156357497"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bcedc8c8-4c05-484c-8edc-8347d8b9b3f4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bcedc8c8-4c05-484c-8edc-8347d8b9b3f4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving PATIENTS.csv to PATIENTS.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rz_itF9_wwHh",
        "outputId": "4a4eaec1-4f4b-44bf-b02a-2dcaa1c33fc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b745bb1-6cbb-4b22-bc64-76e37694f679\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b745bb1-6cbb-4b22-bc64-76e37694f679\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving DIAGNOSES_ICD.csv to DIAGNOSES_ICD.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ujA-gDB9NQ1d",
        "outputId": "4aa8d639-26dd-4fad-9dd5-f829defd504a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cdd8954c-a116-4a10-94fb-fa55f8adce64\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cdd8954c-a116-4a10-94fb-fa55f8adce64\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving ICUSTAYS.csv to ICUSTAYS.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d48PTIMHCUn5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUTk2oa8yStl"
      },
      "source": [
        "# **Calculate the Hospital stay length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0KnahwpxKaY",
        "outputId": "496dbb82-0e61-4a06-e0b5-982d4ff2daec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ROW_ID  SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
            "0      21          22   165315 2196-04-09 12:26:00 2196-04-10 15:54:00   \n",
            "1      22          23   152223 2153-09-03 07:15:00 2153-09-08 19:10:00   \n",
            "2      23          23   124321 2157-10-18 19:34:00 2157-10-25 14:00:00   \n",
            "3      24          24   161859 2139-06-06 16:14:00 2139-06-09 12:48:00   \n",
            "4      25          25   129635 2160-11-02 02:06:00 2160-11-05 14:55:00   \n",
            "\n",
            "  DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
            "0       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
            "1       NaN       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
            "2       NaN      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
            "3       NaN      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
            "4       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
            "\n",
            "          DISCHARGE_LOCATION INSURANCE LANGUAGE           RELIGION  \\\n",
            "0  DISC-TRAN CANCER/CHLDRN H   Private      NaN       UNOBTAINABLE   \n",
            "1           HOME HEALTH CARE  Medicare      NaN           CATHOLIC   \n",
            "2           HOME HEALTH CARE  Medicare     ENGL           CATHOLIC   \n",
            "3                       HOME   Private      NaN  PROTESTANT QUAKER   \n",
            "4                       HOME   Private      NaN       UNOBTAINABLE   \n",
            "\n",
            "  MARITAL_STATUS ETHNICITY            EDREGTIME            EDOUTTIME  \\\n",
            "0        MARRIED     WHITE  2196-04-09 10:06:00  2196-04-09 13:24:00   \n",
            "1        MARRIED     WHITE                  NaN                  NaN   \n",
            "2        MARRIED     WHITE                  NaN                  NaN   \n",
            "3         SINGLE     WHITE                  NaN                  NaN   \n",
            "4        MARRIED     WHITE  2160-11-02 01:01:00  2160-11-02 04:27:00   \n",
            "\n",
            "                                           DIAGNOSIS  HOSPITAL_EXPIRE_FLAG  \\\n",
            "0                            BENZODIAZEPINE OVERDOSE                     0   \n",
            "1  CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS...                     0   \n",
            "2                                         BRAIN MASS                     0   \n",
            "3                     INTERIOR MYOCARDIAL INFARCTION                     0   \n",
            "4                            ACUTE CORONARY SYNDROME                     0   \n",
            "\n",
            "   HAS_CHARTEVENTS_DATA  LENGTH_OF_STAY  \n",
            "0                     1 1 days 03:28:00  \n",
            "1                     1 5 days 11:55:00  \n",
            "2                     1 6 days 18:26:00  \n",
            "3                     1 2 days 20:34:00  \n",
            "4                     1 3 days 12:49:00  \n",
            "58976\n",
            "Are there any null values in the 'LENGTH_OF_STAY' column? False\n"
          ]
        }
      ],
      "source": [
        "admissions_csv_path = \"ADMISSIONS.csv\"\n",
        "patients_csv_path = \"PATIENTS.csv\"\n",
        "diags_csv_path = \"DIAGNOSES_ICD.csv\"\n",
        "icu_csv_path = \"ICUSTAYS.csv\"\n",
        "\n",
        "admissions_df = pd.read_csv(admissions_csv_path)\n",
        "patients_df = pd.read_csv(patients_csv_path)\n",
        "diags_df = pd.read_csv(diags_csv_path)\n",
        "icu_df = pd.read_csv(icu_csv_path)\n",
        "\n",
        "admissions_df['DISCHTIME'].fillna('0',inplace=True)\n",
        "icu_df.OUTTIME.fillna('0',inplace=True)\n",
        "\n",
        "# Convert admission and discharge times to datetime objects\n",
        "admissions_df['ADMITTIME'] = pd.to_datetime(admissions_df['ADMITTIME'])\n",
        "admissions_df['DISCHTIME'] = pd.to_datetime(admissions_df['DISCHTIME'])\n",
        "\n",
        "# Calculate the length of stay for each patient\n",
        "admissions_df['LENGTH_OF_STAY'] = admissions_df['DISCHTIME'] - admissions_df['ADMITTIME']\n",
        "\n",
        "# Display the updated dataframe\n",
        "print(admissions_df.head())\n",
        "print ( len(admissions_df))\n",
        "\n",
        "# Check for null values in the 'LENGTH_OF_STAY' column\n",
        "null_length_of_stay = admissions_df['LENGTH_OF_STAY'].isnull()\n",
        "\n",
        "# Print the result\n",
        "print(\"Are there any null values in the 'LENGTH_OF_STAY' column?\", null_length_of_stay.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ead8PGqkLCpx",
        "outputId": "c9492868-fa4c-49fc-89dd-390985d4beb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ROW_ID  SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
            "0      21          22   165315 2196-04-09 12:26:00 2196-04-10 15:54:00   \n",
            "1      22          23   152223 2153-09-03 07:15:00 2153-09-08 19:10:00   \n",
            "2      23          23   124321 2157-10-18 19:34:00 2157-10-25 14:00:00   \n",
            "3      24          24   161859 2139-06-06 16:14:00 2139-06-09 12:48:00   \n",
            "4      25          25   129635 2160-11-02 02:06:00 2160-11-05 14:55:00   \n",
            "\n",
            "  DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
            "0       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
            "1       NaN       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
            "2       NaN      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
            "3       NaN      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
            "4       NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
            "\n",
            "          DISCHARGE_LOCATION INSURANCE  ... MARITAL_STATUS ETHNICITY  \\\n",
            "0  DISC-TRAN CANCER/CHLDRN H   Private  ...        MARRIED     WHITE   \n",
            "1           HOME HEALTH CARE  Medicare  ...        MARRIED     WHITE   \n",
            "2           HOME HEALTH CARE  Medicare  ...        MARRIED     WHITE   \n",
            "3                       HOME   Private  ...         SINGLE     WHITE   \n",
            "4                       HOME   Private  ...        MARRIED     WHITE   \n",
            "\n",
            "             EDREGTIME            EDOUTTIME  \\\n",
            "0  2196-04-09 10:06:00  2196-04-09 13:24:00   \n",
            "1                  NaN                  NaN   \n",
            "2                  NaN                  NaN   \n",
            "3                  NaN                  NaN   \n",
            "4  2160-11-02 01:01:00  2160-11-02 04:27:00   \n",
            "\n",
            "                                           DIAGNOSIS HOSPITAL_EXPIRE_FLAG  \\\n",
            "0                            BENZODIAZEPINE OVERDOSE                    0   \n",
            "1  CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS...                    0   \n",
            "2                                         BRAIN MASS                    0   \n",
            "3                     INTERIOR MYOCARDIAL INFARCTION                    0   \n",
            "4                            ACUTE CORONARY SYNDROME                    0   \n",
            "\n",
            "  HAS_CHARTEVENTS_DATA  LENGTH_OF_STAY  LENGTH_OF_STAY_DAYS  \\\n",
            "0                    1 1 days 03:28:00             1.144444   \n",
            "1                    1 5 days 11:55:00             5.496528   \n",
            "2                    1 6 days 18:26:00             6.768056   \n",
            "3                    1 2 days 20:34:00             2.856944   \n",
            "4                    1 3 days 12:49:00             3.534028   \n",
            "\n",
            "  Length_of_stay_Bucket  \n",
            "0                     2  \n",
            "1                     6  \n",
            "2                     7  \n",
            "3                     3  \n",
            "4                     4  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "58976\n"
          ]
        }
      ],
      "source": [
        "# First, convert the TimeDelta column to total seconds, and then to days\n",
        "admissions_df['LENGTH_OF_STAY_DAYS'] = admissions_df['LENGTH_OF_STAY'].dt.total_seconds() / (24 * 60 * 60)\n",
        "\n",
        "# Convert the 'LENGTH_OF_STAY_DAYS' column to float\n",
        "admissions_df['LENGTH_OF_STAY_DAYS'] = admissions_df['LENGTH_OF_STAY_DAYS'].astype(float)\n",
        "\n",
        "\n",
        "# Define a function to create the buckets\n",
        "def create_bucket(length_of_stay):\n",
        "    if length_of_stay < 1:\n",
        "        return 1\n",
        "    elif 1 <= length_of_stay <= 7:\n",
        "        return int(length_of_stay) + 1\n",
        "    elif 7 < length_of_stay <= 14:\n",
        "        return 9\n",
        "    else:\n",
        "        return 10\n",
        "\n",
        "# Apply the function to the 'LENGTH_OF_STAY_DAYS' column to create a new 'Length_of_stay_Bucket' column\n",
        "admissions_df['Length_of_stay_Bucket'] = admissions_df['LENGTH_OF_STAY_DAYS'].apply(create_bucket)\n",
        "# Display the updated dataframe\n",
        "print(admissions_df.head())\n",
        "print ( len(admissions_df))\n",
        "\n",
        "#admissions_df = admissions_df.loc[~admissions_df['Length_of_stay_Bucket'].isin([5,6,7,8,9, 10])]\n",
        "#admissions_df = admissions_df.loc[~admissions_df['Length_of_stay_Bucket'].isin([10])]\n",
        "#print(admissions_df.head())\n",
        "#print ( len(admissions_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLHcC-jAKz-2",
        "outputId": "fb9d06bb-3849-4bec-f510-71d6542e8d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ROW_ID  SUBJECT_ID GENDER                  DOB                  DOD  \\\n",
            "0     234         249      F  2075-03-13 00:00:00                  NaN   \n",
            "1     235         250      F  2164-12-27 00:00:00  2188-11-22 00:00:00   \n",
            "2     236         251      M  2090-03-15 00:00:00                  NaN   \n",
            "3     237         252      M  2078-03-06 00:00:00                  NaN   \n",
            "4     238         253      F  2089-11-26 00:00:00                  NaN   \n",
            "\n",
            "              DOD_HOSP DOD_SSN  EXPIRE_FLAG  \n",
            "0                  NaN     NaN            0  \n",
            "1  2188-11-22 00:00:00     NaN            1  \n",
            "2                  NaN     NaN            0  \n",
            "3                  NaN     NaN            0  \n",
            "4                  NaN     NaN            0  \n",
            "46520\n"
          ]
        }
      ],
      "source": [
        "print(patients_df.head())\n",
        "print ( len(patients_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hes0xcm-ZQYP",
        "outputId": "916920d1-3f1c-47a9-bc0e-fc53e0523293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
            "0    1297         109   172335      1.0     40301\n",
            "1    1298         109   172335      2.0       486\n",
            "2    1299         109   172335      3.0     58281\n",
            "3    1300         109   172335      4.0      5855\n",
            "4    1301         109   172335      5.0      4254\n",
            "651047\n"
          ]
        }
      ],
      "source": [
        "print(diags_df.head())\n",
        "print ( len(diags_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdAKGHpFxVHM",
        "outputId": "9ce9e72b-5e61-4ec6-fa28-270d21ca1c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   SUBJECT_ID GENDER                  DOB  DOD  Length_of_stay_Bucket  \\\n",
            "0          22      F  2131-05-07 00:00:00  NaN                      2   \n",
            "1          22      F  2131-05-07 00:00:00  NaN                      2   \n",
            "2          22      F  2131-05-07 00:00:00  NaN                      2   \n",
            "3          22      F  2131-05-07 00:00:00  NaN                      2   \n",
            "4          22      F  2131-05-07 00:00:00  NaN                      2   \n",
            "\n",
            "  ICD9_CODE  \n",
            "0      9678  \n",
            "1      9693  \n",
            "2     E9502  \n",
            "3     E9503  \n",
            "4      3488  \n",
            "1374979\n",
            "1374979\n",
            "Unique values in 'los': {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
            "1374979\n"
          ]
        }
      ],
      "source": [
        "# Merge the dataframes on the 'SUBJECT_ID' column\n",
        "#merged_df = pd.merge(admissions_df, patients_df, diags_df, on='SUBJECT_ID')\n",
        "merged_df_1 = pd.merge(admissions_df, patients_df, on='SUBJECT_ID')\n",
        "merged_df = pd.merge(merged_df_1, diags_df, on='SUBJECT_ID')\n",
        "\n",
        "# Select the desired columns\n",
        "selected_columns = ['SUBJECT_ID', 'GENDER', 'DOB', 'DOD', 'Length_of_stay_Bucket', 'ICD9_CODE']\n",
        "new_dataset = merged_df[selected_columns]\n",
        "#new_dataset = merged_df[selected_columns].copy()\n",
        "\n",
        "# Display the new dataset\n",
        "print(new_dataset.head())\n",
        "print ( len(new_dataset))\n",
        "\n",
        "# Create the all_diags list\n",
        "all_diags = new_dataset['ICD9_CODE'].tolist()\n",
        "\n",
        "print(len(all_diags))\n",
        "\n",
        "# Create a list of length of stay in days (as floats)\n",
        "los = new_dataset['Length_of_stay_Bucket'].tolist()\n",
        "\n",
        "# Get the unique values\n",
        "unique_values = set(los)\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique values in 'los':\", unique_values)\n",
        "print(len(los))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAu2bs_f537S",
        "outputId": "30dd1bad-1649-4862-9db2-831fc4888035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1374979\n"
          ]
        }
      ],
      "source": [
        "print(len(new_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQJEe7E9fixC"
      },
      "source": [
        "# **Create custom Dataset to get sequences and target values (length_of_stay)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRfG9poRfhGS",
        "outputId": "d12635ea-5563-4d76-eaee-742146977b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique class labels: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
            "Unique class labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Preprocess your data (You should preprocess the data to create sequences and targets)\n",
        "\n",
        "# Example: sequences, targets = preprocess(new_dataset)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.sequences[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        #return torch.tensor(sequence, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
        "        return sequence,target\n",
        "\n",
        "unique_labels1 = set(los)\n",
        "print(f\"Unique class labels: {unique_labels1}\")\n",
        "\n",
        "los_zero_indexed = [x - 1 for x in los]\n",
        "dataset = CustomDataset(all_diags, los_zero_indexed)\n",
        "#dataset = CustomDataset(all_diags, los)\n",
        "unique_labels = set(los_zero_indexed)\n",
        "print(f\"Unique class labels: {unique_labels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFP6bVtpfhq_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djsHISaeyv02"
      },
      "source": [
        "# **Create Train , Validation and Test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RnKeJQxk94",
        "outputId": "2859ab9e-3bd9-4e1d-e63a-29606edfe0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 4\n",
            "Length of val dataset: 2\n",
            "Length of test dataset: 1\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "split = int(len(dataset)*0.7)\n",
        "\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, val_test_dataset = random_split(dataset, lengths)\n",
        "\n",
        "\n",
        "split = int(len(val_test_dataset)*0.7)\n",
        "lengths = [split, len(val_test_dataset) - split]\n",
        "val_dataset, test_dataset = random_split(val_test_dataset, lengths)\n",
        "\n",
        "\n",
        "print(\"Length of train dataset:\", len(train_dataset))\n",
        "print(\"Length of val dataset:\", len(val_dataset))\n",
        "print(\"Length of test dataset:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4gODpDAWhC3",
        "outputId": "08093bff-dfab-4cd5-e5d8-ba17c728387a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6985"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Get dictionary index for all ICD9 codes\n",
        "icd_uniq = diags_df.ICD9_CODE.unique()\n",
        "# icd_uniq = ['A', 'B', 'A']\n",
        "icd_dic = {}\n",
        "i = 0\n",
        "for code in icd_uniq:\n",
        "    icd_dic[code] = i\n",
        "    i += 1\n",
        "len(icd_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye9CvAaxWqrh"
      },
      "outputs": [],
      "source": [
        "def collate_fn(data):\n",
        "    \n",
        "    #sequences, labels = zip(*data)\n",
        "    sequences, length_of_stay_Bucket = zip(*data)\n",
        "    \n",
        "    # Create tensors for length_of_stay\n",
        "    y = torch.tensor(length_of_stay_Bucket, dtype=torch.int64)\n",
        "\n",
        "    #num_patients = len(sequences)\n",
        "    #num_visits = [len(patient) for patient in sequences]\n",
        "    #num_codes = [len(visit) for patient in sequences for visit in patient]\n",
        "\n",
        "\n",
        "    def is_iterable(obj):\n",
        "         try:\n",
        "             iter(obj)\n",
        "             return True\n",
        "         except TypeError:\n",
        "              return False\n",
        "\n",
        "    num_patients = len(sequences)\n",
        "    #num_visits = [len(patient) for patient in sequences if is_iterable(patient)]\n",
        "    #num_codes = [len(visit) for patient in sequences for visit in patient]\n",
        "    #num_codes = [len(visit) for patient in sequences for visit in patient if is_iterable(patient) and is_iterable(visit)]\n",
        "\n",
        "\n",
        "    max_num_visits = 42 #max(num_visits)\n",
        "    max_num_codes = 39 #max(num_codes)\n",
        "#     print(max_num_visits, max_num_codes, len(y) )\n",
        "    #x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.float)\n",
        "    x = torch.zeros((num_patients, max_num_codes), dtype=torch.float)\n",
        "    for i_patient, patient in enumerate(sequences):\n",
        "        #for j_visit, visit in enumerate(patient):\n",
        "            for k_diag, diag in enumerate(sequences):\n",
        "                if diag != diag:\n",
        "#                     #print(diag, i_patient, j_visit,k_diag) \n",
        "                    continue\n",
        "                #else: x[i_patient, j_visit,k_diag ] =icd_dic[diag]\n",
        "                else: x[i_patient, k_diag] = icd_dic.get(diag, 0)\n",
        "    #x = x.type(torch.LongTensor)\n",
        "    #y = y.type(torch.LongTensor)\n",
        "    return x, y\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMu07S9KzBPk"
      },
      "source": [
        "# **Load the inital data into train_loader, val_loader, test_loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulumcFnZzO_B"
      },
      "outputs": [],
      "source": [
        "def load_data(train_dataset, val_dataset, test_dataset, batch_size, collate_fn):\n",
        "    batch_size = batch_size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "batch_size = 128\n",
        "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset, batch_size, collate_fn)\n",
        "\n",
        "in_feature = 39\n",
        "seq_len = 42\n",
        "n_heads = 32\n",
        "factor = 5 # M - dense interpolation factor\n",
        "num_class = 10\n",
        "num_layers = 1 #N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu0P75NfEK9w"
      },
      "outputs": [],
      "source": [
        "from sand_144 import SAnD, MyNeuralNetworkClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxkZ6uRCCoxv"
      },
      "source": [
        "# **Import Sand and relevant classes to run our Training and evaluate job**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3cSP1O1Cnqy"
      },
      "outputs": [],
      "source": [
        "\n",
        "clf = MyNeuralNetworkClassifier(\n",
        "    SAnD(in_feature, seq_len, n_heads, factor, num_class, num_layers),\n",
        "    nn.CrossEntropyLoss(),\n",
        "    optim.Adam, optimizer_config={\"lr\": 1e-5, \"betas\": (0.9, 0.98), \"eps\": 4e-09, \"weight_decay\": 5e-4},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "lhNuRzqy_pZ7",
        "outputId": "04addf53-53b6-45df-fe08-35b13556bace"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-1f369316ed09>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m clf.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     {\"train\": train_loader,\n\u001b[1;32m      4\u001b[0m      \"val\": val_loader},\n\u001b[1;32m      5\u001b[0m      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Project/sand_144.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, loader, epochs, checkpoint_path, validation)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen_of_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;31m#                 print(x.shape, y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mb_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-07b36f37ae52>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m#else: x[i_patient, j_visit,k_diag ] =icd_dic[diag]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_patient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_diag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micd_dic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m#x = x.type(torch.LongTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#y = y.type(torch.LongTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ],
      "source": [
        "# training network\n",
        "clf.fit(\n",
        "    {\"train\": train_loader,\n",
        "     \"val\": val_loader},\n",
        "     epochs= 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNZoUhe2NvDI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}